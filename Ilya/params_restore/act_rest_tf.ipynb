{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f64ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657bac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad67b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_perceptron(layers, activation_function = None, input_shape = None):\n",
    "    if activation_function is None:\n",
    "        activation_function = 'leaky_relu'\n",
    "    model = tf.keras.Sequential([tf.keras.layers.Dense(l, activation_function) for l in layers])\n",
    "    if input_shape is not None:\n",
    "        model.build(input_shape)\n",
    "    return model\n",
    "\n",
    "class activity_container:\n",
    "    def __init__(self, activity, time_interval, ignore = None, optimizer = None):\n",
    "        if ignore is None:\n",
    "            ignore = []\n",
    "        self.time_interval = time_interval\n",
    "        self.resolution = activity.shape[0]\n",
    "        self.optimizer = tf.keras.optimizers.Adam() if optimizer is None else optimizer\n",
    "        self.activity = activity\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, t):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        pass\n",
    "\n",
    "    @tf.function\n",
    "    def loss(self):\n",
    "        time = tf.reshape(tf.linspace(self.time_interval[0], self.time_interval[1], self.resolution), (self.resolution, 1))\n",
    "        return tf.reduce_mean((self(time) - self.activity)**2)\n",
    "\n",
    "    def optimize(self, epochs):\n",
    "        LH = []\n",
    "        for _ in range(epochs):\n",
    "            with tf.GradientTape() as tape:\n",
    "                loss_value = self.loss()\n",
    "                grads = tape.gradient(loss_value, self.params)\n",
    "                self.optimizer.apply_gradients(zip(grads, self.params))\n",
    "            LH.append(loss_value.numpy())\n",
    "        return LH\n",
    "\n",
    "class model_container(activity_container):\n",
    "    def __init__(self, model, activity, time_interval, ignore=None, optimizer=None):\n",
    "        super().__init__(activity, time_interval, ignore, optimizer)\n",
    "        self.model:tf.keras.Model = model\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        return self.model.trainable_variables\n",
    "    \n",
    "    @tf.function\n",
    "    def __call__(self, time):\n",
    "        return self.model(time)\n",
    "\n",
    "class furie_container(model_container):\n",
    "    def __init__(self, activity, time_interval, ignore=None, optimizer=None):\n",
    "        m = tf.keras.layers.Dense(activity.shape[1], tf.sin, bias_initializer='random_uniform')\n",
    "        m.build(1)\n",
    "        super().__init__(m, activity, time_interval, ignore, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ca330",
   "metadata": {},
   "outputs": [],
   "source": [
    "class activity_restorer:\n",
    "    def __init__(self, weights, container, indexes_to_restore):\n",
    "        self.weights = tf.Variable(weights)\n",
    "        self.container:activity_container = container\n",
    "        self.indexes_to_restore = tf.constant(indexes_to_restore, tf.int32)\n",
    "\n",
    "    @tf.function\n",
    "    def dx_dt(self, time):\n",
    "        self.activity_function(time) @ self.weights @ self.activity_function(time)\n",
    "\n",
    "    @tf.function\n",
    "    def da_dt(self, time):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(time)\n",
    "            grad = tape.gradient(time, self.activity_function(time))\n",
    "        return grad\n",
    "\n",
    "    @tf.function\n",
    "    def loss_activity_dire(self):\n",
    "        loss = 0.0\n",
    "        for ti in range(self.time_count):\n",
    "            t = self.time[ti]\n",
    "            loss += tf.reduce_mean((self.dx_dt(ti) - self.da_dt(tf.reshape(t, (1, 1))))**2)\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def grad_step(self):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.absolute_activity_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d45b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class solver:\n",
    "  def __init__(self, dt = 0.1, **rules):\n",
    "    self.rules = rules\n",
    "    self.params = rules.keys()\n",
    "    self.dt = dt\n",
    "\n",
    "  def update(self):\n",
    "    self.set_to(**{name:getattr(self, name) + self.rules[name](**{name:getattr(self, name) for name in self.rules})*self.dt for name in self.rules})\n",
    "\n",
    "  def set_to(self, **values):\n",
    "    for j in values:\n",
    "      setattr(self, j, values[j])\n",
    "\n",
    "  def solve(self, t_end, t_start = 0):\n",
    "    self.t = t_start\n",
    "    history = {name:[] for name in self.rules}\n",
    "    history['t'] = []\n",
    "    while self.t < t_end:\n",
    "      self.update()\n",
    "      for j in history:\n",
    "        history[j].append(getattr(self, j))\n",
    "      self.t += self.dt\n",
    "    delattr(self, 't')\n",
    "    for j in history:\n",
    "      history[j] = np.array(history[j])\n",
    "    return history\n",
    "\n",
    "class xwx(solver):\n",
    "    def __init__(self, W, dt=0.1):\n",
    "        self.W = W\n",
    "        super().__init__(dt, x = lambda x: x @ self.W @ x)\n",
    "\n",
    "def xwx_ddx_dt_dx(x, w):\n",
    "    \"dx/dt [t] respect to x[q] = xwx_dx_dt_dx(x, w, t)[i][q]\"\n",
    "    return w @ x + x @ w\n",
    "\n",
    "def generate_connections(groups, group_complexity, group_density = 0.5, noise = 1, noise_density = 0.3, group_recurent_rate = 0.5):\n",
    "    return \\\n",
    "    np.repeat(np.repeat((1-group_recurent_rate)*(np.random.sample([groups, groups]) < group_density) + group_recurent_rate*np.eye(groups, groups), group_complexity, 0), group_complexity, 1) * np.random.uniform(-1, 1, [group_complexity*groups]*2) + \\\n",
    "    noise * np.random.uniform(-1, 1, [group_complexity*groups]*2) * (np.random.sample([group_complexity*groups]*2) < noise_density) # skip connections\n",
    "\n",
    "def generate_multiple_connections(C):\n",
    "    N = C.shape[0]\n",
    "    return (np.random.uniform(-1, 1, [N]*3)) * C\n",
    "\n",
    "def generate_activity(W, t_end = 10, dt = 0.001):\n",
    "    s = xwx(W, dt = dt)\n",
    "    s.x = np.random.uniform(-1, 1, W.shape[0])\n",
    "    h = s.solve(t_end)\n",
    "    return h\n",
    "\n",
    "def add_axis(a):\n",
    "    return np.reshape(a, (-1, 1))\n",
    "\n",
    "def generate_dataset(activity):\n",
    "    dx_dt = (activity['x'][1:] - activity['x'][:-1]) / add_axis(activity['t'][1:] - activity['t'][:-1])\n",
    "    xx = np.array([np.kron(x, x).flatten() for x in activity['x']])\n",
    "    return xx[:-1], dx_dt\n",
    "\n",
    "def plot_activity(d, var_count = 2):\n",
    "    fig, ax = plt.subplots(var_count, 1)\n",
    "    for n, i in enumerate(ax):\n",
    "        i.plot(d['t'], d['x'][:, n])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0ab2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "w = np.random.uniform(-1, 1, (N, N, N))\n",
    "w = 5*(w - w.T)\n",
    "activity_t = generate_activity(w, 1)\n",
    "plot_activity(activity_t, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5c7a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = model_container(form_perceptron([20, 40, 50, activity_t['x'].shape[1]], input_shape=[1, 1], activation_function='leaky_relu'), activity_t['x'], (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d51a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f.optimize(1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d24d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.linspace(0, 1, 100)\n",
    "output = f(tf.reshape(t, (100, 1))).numpy()\n",
    "plot_activity({'x':output, 't':t}, 3)\n",
    "plot_activity(activity_t, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
